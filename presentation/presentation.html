<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GraphSAGE: Inductive Representation Learning on Large Graphs</title>
    <style>
        :root {
            --font-family-display: Arial, sans-serif;
            --font-weight-display: 600;
            --font-family-content: Arial, sans-serif;
            --font-weight-content: 400;
            --font-size-content: 16px;
            --line-height-content: 1.4;
        }

        body.theme-dark {
            --color-bg-base: #0f172a;
            --color-bg-elevated: #020617;
            --color-bg-surface: #1e293b;
            --color-bg-muted: #334155;
            --color-text-primary: #f1f5f9;
            --color-text-secondary: #cbd5e1;
            --color-text-muted: #94a3b8;
            --color-text-accent: #38bdf8;
            --color-primary: #38bdf8;
            --color-primary-foreground: #0f172a;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-family-content);
            font-weight: var(--font-weight-content);
            font-size: var(--font-size-content);
            line-height: var(--line-height-content);
            overflow-x: hidden;
        }

        .slide {
            width: 960px;
            height: 540px;
            margin: 0 auto 20px;
            display: flex;
            flex-shrink: 0;
            position: relative;
            overflow: hidden;
        }

        .row { flex-direction: row; }
        .col { flex-direction: column; }
        .center {
            justify-content: center;
            align-items: center;
            text-align: center;
        }
        .items-center { align-items: center; }
        .items-start { align-items: flex-start; }
        .fill-width { flex: 1; }
        .fill-height { flex: 1; display: flex; flex-direction: column; }

        .gap-sm { gap: 0.5rem; }
        .gap-md { gap: 1rem; }
        .gap-lg { gap: 1.5rem; }
        .gap-xl { gap: 2rem; }

        .p-4 { padding: 1rem; }
        .p-6 { padding: 1.5rem; }
        .p-8 { padding: 2rem; }
        .p-12 { padding: 3rem; }
        .p-16 { padding: 4rem; }

        .mb-2 { margin-bottom: 0.5rem; }
        .mb-4 { margin-bottom: 1rem; }
        .mb-6 { margin-bottom: 1.5rem; }
        .mb-8 { margin-bottom: 2rem; }
        .mb-12 { margin-bottom: 3rem; }

        .mt-2 { margin-top: 0.5rem; }
        .mt-4 { margin-top: 1rem; }
        .mt-6 { margin-top: 1.5rem; }
        .mt-8 { margin-top: 2rem; }

        h1, h2, h3, h4, h5, h6 {
            font-family: var(--font-family-display);
            font-weight: var(--font-weight-display);
            line-height: 1.2;
            margin: 0;
        }

        h1 { font-size: 3rem; }
        h2 { font-size: 2.25rem; }
        h3 { font-size: 1.75rem; }

        .text-6xl { font-size: 3.75rem; }
        .text-5xl { font-size: 3rem; }
        .text-4xl { font-size: 2.25rem; }
        .text-3xl { font-size: 1.875rem; }
        .text-2xl { font-size: 1.5rem; }
        .text-xl { font-size: 1.25rem; }
        .text-lg { font-size: 1.125rem; }

        .text-center { text-align: center; }
        .text-left { text-align: left; }

        .opacity-90 { opacity: 0.9; }
        .opacity-80 { opacity: 0.8; }

        ul, ol {
            margin-left: 2rem;
            line-height: 1.8;
        }

        li { 
            margin-bottom: 0.75rem;
            list-style: disc;
        }

        li:last-child { margin-bottom: 0; }

        p {
            margin: 0;
            line-height: 1.6;
        }

        .card-rect {
            padding: 2rem;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
        }

        code {
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            padding: 2px 6px;
            background-color: #1e293b;
            color: #38bdf8;
            border-radius: 3px;
        }
    </style>
</head>
<body class="theme-dark">

    <!-- Slide 1: Title Slide -->
    <section class="slide p-16 col center" style="background-color: #020617; color: #f1f5f9;">
        <h1 class="text-6xl mb-4" style="color: #38bdf8;">GraphSAGE</h1>
        <p class="text-2xl mb-12" style="color: #cbd5e1;">Inductive Representation Learning on Large Graphs</p>
        <p class="text-lg" style="color: #94a3b8;">Hamilton, Ying, and Leskovec (2017)</p>
        <p class="text-sm mt-8" style="color: #94a3b8;">Understanding the Problem → The Solution → Applications</p>
    </section>

    <!-- Slide 2: What is a Graph? -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">What is a Graph?</h2>
        <div class="fill-height">
            <ul class="text-lg" style="color: #cbd5e1;">
                <li><strong>Nodes:</strong> Entities or objects (people, papers, molecules)</li>
                <li><strong>Edges:</strong> Connections or relationships between nodes</li>
                <li><strong>Features:</strong> Attributes on nodes/edges (text, properties)</li>
                <li><strong>Real examples:</strong> Social networks, citation networks, molecules, knowledge graphs</li>
            </ul>
        </div>
    </section>

    <!-- Slide 3: Graph Examples -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Graphs Are Everywhere</h2>
        <div class="fill-height row gap-lg">
            <div class="fill-width" style="background-color: #1e293b; color: #f1f5f9; padding: 1.5rem; box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);">
                <h3 style="color: #38bdf8; margin-bottom: 1rem;">Social Networks</h3>
                <p style="color: #cbd5e1; font-size: 0.95rem;">People as nodes, friendships as edges</p>
            </div>
            <div class="fill-width" style="background-color: #1e293b; color: #f1f5f9; padding: 1.5rem; box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);">
                <h3 style="color: #38bdf8; margin-bottom: 1rem;">Citation Networks</h3>
                <p style="color: #cbd5e1; font-size: 0.95rem;">Papers as nodes, citations as edges</p>
            </div>
            <div class="fill-width" style="background-color: #1e293b; color: #f1f5f9; padding: 1.5rem; box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);">
                <h3 style="color: #38bdf8; margin-bottom: 1rem;">Molecules</h3>
                <p style="color: #cbd5e1; font-size: 0.95rem;">Atoms as nodes, bonds as edges</p>
            </div>
        </div>
    </section>

    <!-- Slide 4: Graph Prediction Tasks -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Graph Prediction Tasks</h2>
        <div class="fill-height">
            <ul class="text-lg" style="color: #cbd5e1;">
                <li><strong>Node-level:</strong> Predict properties of individual nodes (classification, regression)</li>
                <li><strong>Edge-level:</strong> Predict relationships between node pairs</li>
                <li><strong>Graph-level:</strong> Predict properties of entire graphs</li>
            </ul>
            <p class="mt-8" style="color: #94a3b8; font-size: 1rem;"><em>GraphSAGE focuses on node-level tasks with unseen nodes</em></p>
        </div>
    </section>

    <!-- Slide 5: Introduction to GNNs -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">What is a Graph Neural Network?</h2>
        <p class="text-lg mb-8" style="color: #cbd5e1;"><strong>A learnable transformation</strong> on graph attributes that:</p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Updates node/edge/graph features using <strong>neural networks</strong></li>
            <li><strong>Respects graph structure</strong> by aggregating information from neighbors</li>
            <li>Is <strong>permutation invariant</strong> (order of nodes doesn't matter)</li>
        </ul>
    </section>

    <!-- Slide 6: Core GNN Operation - Message Passing -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-4" style="color: #38bdf8;">Message Passing: The Core Idea</h2>
        <p class="text-lg mb-6" style="color: #cbd5e1;"><strong>Three steps repeated at each layer:</strong></p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>1. Gather:</strong> Collect embeddings from all neighboring nodes</li>
            <li><strong>2. Aggregate:</strong> Combine neighbors' info (sum, mean, max, etc.)</li>
            <li><strong>3. Update:</strong> Pass through neural network with own features</li>
        </ul>
    </section>

    <!-- Slide 7: Message Passing Visualization -->
    <section class="slide p-16 col center" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-8" style="color: #38bdf8;">Message Passing Analogy</h2>
        <p class="text-lg" style="color: #cbd5e1;"><strong style="color: #f1f5f9;">Convolutional Neural Networks (Images)</strong></p>
        <p style="color: #94a3b8; margin-bottom: 1rem;">Each pixel aggregates info from neighboring pixels (grid structure)</p>
        <p class="text-lg" style="color: #cbd5e1;"><strong style="color: #f1f5f9;">Graph Neural Networks (General Graphs)</strong></p>
        <p style="color: #94a3b8;">Each node aggregates info from neighboring nodes (variable structure)</p>
    </section>

    <!-- Slide 8: State of Art - The Problem -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Before GraphSAGE: The Problem</h2>
        <p class="text-lg mb-6" style="color: #cbd5e1;"><strong>Most node embedding methods were <span style="color: #fbbf24;">TRANSDUCTIVE</span></strong></p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Each node gets a unique, fixed embedding vector</li>
            <li>When new nodes appear: <strong>must recompute everything from scratch</strong></li>
            <li>100-500x slower for test nodes than training nodes</li>
        </ul>
    </section>

    <!-- Slide 9: Examples of Transductive Methods -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Transductive Approaches: DeepWalk & Node2Vec</h2>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>Core Idea:</strong> Random walks capture network structure</p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Sample random walks through graph</li>
            <li>Apply word2vec-style embedding learning</li>
            <li><strong>Problem:</strong> Learn unique vector per node, not a <strong>function</strong></li>
        </ul>
    </section>

    <!-- Slide 10: The Orthogonal Invariance Problem -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Critical Issue: Orthogonal Invariance</h2>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>Random walk objectives optimize:</strong></p>
        <p class="text-base mb-4" style="color: #94a3b8; font-family: 'Courier New', monospace;">Z^T × Z ≈ M  (for some matrix M)</p>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>The Problem:</strong></p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Can rotate arbitrarily: (Q × Z)^T × (Q × Z) = Z^T × Z</li>
            <li><strong>Embedding spaces drift</strong> when new nodes added</li>
            <li><strong>No cross-graph generalization</strong> possible</li>
        </ul>
    </section>

    <!-- Slide 11: GCN Limitations -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Graph Convolutional Networks (GCN)</h2>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>Kipf & Welling (2016):</strong> Apply convolutions to graphs</p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>✓ Uses node features</strong></li>
            <li>✗ <strong>Requires full graph:</strong> Must know entire graph at training</li>
            <li>✗ <strong>Transductive only:</strong> Fixed graph, can't handle unseen nodes</li>
            <li>✗ <strong>Doesn't scale:</strong> Needs full graph Laplacian</li>
        </ul>
    </section>

    <!-- Slide 12: The GraphSAGE Insight -->
    <section class="slide p-16 col center" style="background-color: #020617; color: #f1f5f9;">
        <h2 class="text-4xl mb-12" style="color: #38bdf8;">The Key Insight</h2>
        <p class="text-xl" style="color: #cbd5e1;"><strong>Don't learn embeddings for each node...</strong></p>
        <p class="text-xl mt-8" style="color: #fbbf24;"><strong>Learn a FUNCTION that generates embeddings</strong></p>
        <p class="text-sm mt-12" style="color: #94a3b8;">By sampling & aggregating neighborhood features</p>
    </section>

    <!-- Slide 13: GraphSAGE Overview -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">GraphSAGE: Inductive Framework</h2>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>Core Principle:</strong> Sample + Aggregate</p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Learn <strong>aggregator functions</strong> (not node embeddings)</li>
            <li>For any node v: <strong>sample neighbors, aggregate their features</strong></li>
            <li>Pass through learned neural networks</li>
            <li><strong>Inference:</strong> Apply same function to unseen nodes</li>
        </ul>
    </section>

    <!-- Slide 14: GraphSAGE Algorithm - High Level -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-4" style="color: #38bdf8;">GraphSAGE Forward Pass (K=2 layers)</h2>
        <p style="color: #94a3b8; font-size: 0.95rem; margin-bottom: 0.5rem;"><strong style="color: #f1f5f9;">Layer 1:</strong> Node gets info from 1-hop neighbors</p>
        <p style="color: #94a3b8; font-size: 0.95rem; margin-bottom: 1.5rem;"><strong style="color: #f1f5f9;">Layer 2:</strong> Node gets info from 2-hop neighbors</p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Sample ~25 neighbors at each hop (configurable)</li>
            <li>Recursively aggregate their embeddings</li>
            <li>Concatenate with own features</li>
            <li>Pass through neural network layer</li>
        </ul>
    </section>

    <!-- Slide 15: Mathematical Formulation -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-4" style="color: #38bdf8;">GraphSAGE: Mathematical Formulation</h2>
        <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 1rem; font-family: 'Courier New', monospace;"><strong style="color: #f1f5f9;">h^0_v = x_v</strong> (initialize with input features)</p>
        <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 1rem; font-family: 'Courier New', monospace;"><strong style="color: #f1f5f9;">h^k_N(v) = AGGREGATE_k({h^(k-1)_u : u ∈ N(v)})</strong> (aggregate neighbors)</p>
        <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 2rem; font-family: 'Courier New', monospace;"><strong style="color: #f1f5f9;">h^k_v = σ(W^k || [h^(k-1)_v, h^k_N(v)])</strong> (concat + transform)</p>
        <p style="color: #94a3b8; font-size: 0.9rem; font-family: 'Courier New', monospace;"><strong style="color: #f1f5f9;">z_v = h^K_v</strong> (final embedding)</p>
    </section>

    <!-- Slide 16: Three Aggregator Functions -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Three Aggregator Architectures</h2>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>Mean Aggregator:</strong> Simple average of neighbor embeddings</li>
            <li><strong>LSTM Aggregator:</strong> Sequential processing (more expressive)</li>
            <li><strong>Pooling Aggregator:</strong> Element-wise max over MLP outputs</li>
        </ul>
    </section>

    <!-- Slide 17: Why GraphSAGE Works -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Why GraphSAGE Solves the Problems</h2>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>✓ Inductive:</strong> Same function works for unseen nodes</li>
            <li><strong>✓ No drift:</strong> Grounded in node features, not abstract vectors</li>
            <li><strong>✓ Uses features:</strong> Node attributes are the foundation</li>
            <li><strong>✓ Scalable:</strong> Fixed neighborhood size (e.g., 25 nodes)</li>
        </ul>
    </section>

    <!-- Slide 18: Key Innovation - Sampling -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">The Sampling Strategy</h2>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>For large graphs, use all neighbors = computationally expensive</strong></p>
        <p class="text-lg mb-6" style="color: #fbbf24;"><strong>GraphSAGE solution: Fixed-size sampling</strong></p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li>Sample ~25 neighbors per hop (instead of all)</li>
            <li>Neighborhood size grows as <strong>O(k^L)</strong> where L = layers</li>
            <li>Enables mini-batch training on massive graphs</li>
        </ul>
    </section>

    <!-- Slide 19: Comparison - Old vs GraphSAGE -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Comparison: Transductive vs Inductive</h2>
        <div class="fill-height row gap-lg">
            <div class="fill-width" style="background-color: #1e293b; color: #f1f5f9; padding: 1.5rem; box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);">
                <h3 style="color: #38bdf8; margin-bottom: 0.8rem; font-size: 1.5rem;">Transductive</h3>
                <p style="color: #cbd5e1; font-size: 0.95rem; margin-bottom: 0.5rem;">• Unique embedding per node</p>
                <p style="color: #cbd5e1; font-size: 0.95rem; margin-bottom: 0.5rem;">• ✗ Can't handle new nodes</p>
                <p style="color: #cbd5e1; font-size: 0.95rem;">• ✗ 100-500x slower inference</p>
            </div>
            <div class="fill-width" style="background-color: #1e293b; color: #f1f5f9; padding: 1.5rem; box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);">
                <h3 style="color: #38bdf8; margin-bottom: 0.8rem; font-size: 1.5rem;">GraphSAGE</h3>
                <p style="color: #cbd5e1; font-size: 0.95rem; margin-bottom: 0.5rem;">• Learned aggregation function</p>
                <p style="color: #cbd5e1; font-size: 0.95rem; margin-bottom: 0.5rem;">• ✓ Direct inference on new nodes</p>
                <p style="color: #cbd5e1; font-size: 0.95rem;">• ✓ Scalable & generalizable</p>
            </div>
        </div>
    </section>

    <!-- Slide 20: Experimental Results -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Experimental Results</h2>
        <p class="text-lg mb-4" style="color: #cbd5e1;"><strong>Three benchmarks tested:</strong></p>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>Citation networks:</strong> Classifying unseen papers</li>
            <li><strong>Reddit posts:</strong> Subreddit prediction for new posts</li>
            <li><strong>Protein-protein interactions:</strong> Cross-graph generalization</li>
        </ul>
        <p class="text-lg mt-6" style="color: #fbbf24;"><strong>Key Finding:</strong> 51% improvement over features alone, 100x faster than transductive baseline</p>
    </section>

    <!-- Slide 21: Why This Matters -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Why GraphSAGE Matters</h2>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>Dynamic graphs:</strong> Real-world networks constantly evolve</li>
            <li><strong>Production systems:</strong> New users/items arrive continuously</li>
            <li><strong>Scalability:</strong> Massive graphs (billions of nodes)</li>
            <li><strong>Generalization:</strong> Transfer learning across graphs</li>
        </ul>
    </section>

    <!-- Slide 22: Real-World Applications -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Real-World Applications</h2>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>Recommendation systems:</strong> Embedding new users/products</li>
            <li><strong>Social networks:</strong> Community detection for new accounts</li>
            <li><strong>Fraud detection:</strong> Classifying new transactions</li>
            <li><strong>Drug discovery:</strong> Molecular property prediction</li>
        </ul>
    </section>

    <!-- Slide 23: Summary & Key Takeaways -->
    <section class="slide p-16 col" style="background-color: #0f172a; color: #f1f5f9;">
        <h2 class="mb-6" style="color: #38bdf8;">Key Takeaways</h2>
        <ul class="text-lg" style="color: #cbd5e1;">
            <li><strong>Problem:</strong> Transductive methods can't handle new nodes efficiently</li>
            <li><strong>Solution:</strong> Learn aggregation <strong>functions</strong>, not node embeddings</li>
            <li><strong>Innovation:</strong> Sample fixed-size neighborhoods for scalability</li>
            <li><strong>Impact:</strong> Enables inductive learning on billion-node graphs</li>
        </ul>
    </section>

    <!-- Slide 24: Thank You -->
    <section class="slide p-16 col center" style="background-color: #020617; color: #f1f5f9;">
        <h2 class="text-5xl mb-6" style="color: #38bdf8;">Thank You!</h2>
        <p class="text-xl" style="color: #cbd5e1;">Questions?</p>
        <p class="text-sm mt-8" style="color: #94a3b8;">Hamilton, W. L., Ying, R., & Leskovec, J. (2017). Inductive Representation Learning on Large Graphs. NIPS 2017.</p>
    </section>

</body>
</html>
